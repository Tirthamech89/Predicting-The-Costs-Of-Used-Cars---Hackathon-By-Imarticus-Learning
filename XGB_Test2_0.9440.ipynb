{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import pickle\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# Comment this if the data visualisations doesn't work on your side\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_excel('C:/Users/Desktop/ML_Hack/Participants_Data_Used_Cars/Data_Train.xlsx')\n",
    "test = pd.read_excel('C:/Users/Desktop/ML_Hack/Participants_Data_Used_Cars/Data_Test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Name']=train['Name'].str.strip()\n",
    "train['Name']=train['Name'].str.upper()\n",
    "test['Name']=test['Name'].str.strip()\n",
    "test['Name']=test['Name'].str.upper()\n",
    "\n",
    "\n",
    "train['Location']=train['Location'].str.strip()\n",
    "train['Location']=train['Location'].str.upper()\n",
    "test['Location']=test['Location'].str.strip()\n",
    "test['Location']=test['Location'].str.upper()\n",
    "\n",
    "train['Fuel_Type']=train['Fuel_Type'].str.strip()\n",
    "train['Fuel_Type']=train['Fuel_Type'].str.upper()\n",
    "test['Fuel_Type']=test['Fuel_Type'].str.strip()\n",
    "test['Fuel_Type']=test['Fuel_Type'].str.upper()\n",
    "\n",
    "\n",
    "train['Transmission']=train['Transmission'].str.strip()\n",
    "train['Transmission']=train['Transmission'].str.upper()\n",
    "test['Transmission']=test['Transmission'].str.strip()\n",
    "test['Transmission']=test['Transmission'].str.upper()\n",
    "\n",
    "\n",
    "train['Owner_Type']=train['Owner_Type'].str.strip()\n",
    "train['Owner_Type']=train['Owner_Type'].str.upper()\n",
    "test['Owner_Type']=test['Owner_Type'].str.strip()\n",
    "test['Owner_Type']=test['Owner_Type'].str.upper()\n",
    "\n",
    "\n",
    "\n",
    "train['Mileage']=train['Mileage'].str.strip()\n",
    "train['Mileage']=train['Mileage'].str.upper()\n",
    "test['Mileage']=test['Mileage'].str.strip()\n",
    "test['Mileage']=test['Mileage'].str.upper()\n",
    "\n",
    "\n",
    "\n",
    "train['Engine']=train['Engine'].str.strip()\n",
    "train['Engine']=train['Engine'].str.upper()\n",
    "test['Engine']=test['Engine'].str.strip()\n",
    "test['Engine']=test['Engine'].str.upper()\n",
    "\n",
    "\n",
    "\n",
    "train['Power']=train['Power'].str.strip()\n",
    "train['Power']=train['Power'].str.upper()\n",
    "test['Power']=test['Power'].str.strip()\n",
    "test['Power']=test['Power'].str.upper()\n",
    "\n",
    "\n",
    "\n",
    "train['New_Price']=train['New_Price'].str.strip()\n",
    "train['New_Price']=train['New_Price'].str.upper()\n",
    "test['New_Price']=test['New_Price'].str.strip()\n",
    "test['New_Price']=test['New_Price'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Outlier Treatment:\n",
    "\n",
    "#train=train[(train['Kilometers_Driven']  > 999) & (train['Kilometers_Driven'] < 6500000)]\n",
    "#train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6019, 13)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tg=train[['Price']]\n",
    "del train['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data=pd.concat([train,test])\n",
    "all_data = all_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_data['CR_fg']=np.where(all_data['New_Price'].str.contains('CR',na=False),1,0)\n",
    "#all_data['LAKH_fg']=np.where(all_data['New_Price'].str.contains('LAKH',na=False),1,0)\n",
    "#all_data['KMKG_fg']=np.where(all_data['Mileage'].str.contains('KM/KG',na=False),1,0)\n",
    "#all_data['KMPL_fg']=np.where(all_data['Mileage'].str.contains('KMPL',na=False),1,0)\n",
    "#all_data['NULL_fg']=np.where(all_data['Power'].str.contains('NULL',na=False),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Year</th>\n",
       "      <th>Kilometers_Driven</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Owner_Type</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Engine</th>\n",
       "      <th>Power</th>\n",
       "      <th>Seats</th>\n",
       "      <th>New_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MARUTI WAGON R LXI CNG</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>2010</td>\n",
       "      <td>72000</td>\n",
       "      <td>CNG</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>FIRST</td>\n",
       "      <td>26.6 KM/KG</td>\n",
       "      <td>998 CC</td>\n",
       "      <td>58.16 BHP</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HYUNDAI CRETA 1.6 CRDI SX OPTION</td>\n",
       "      <td>PUNE</td>\n",
       "      <td>2015</td>\n",
       "      <td>41000</td>\n",
       "      <td>DIESEL</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>FIRST</td>\n",
       "      <td>19.67 KMPL</td>\n",
       "      <td>1582 CC</td>\n",
       "      <td>126.2 BHP</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HONDA JAZZ V</td>\n",
       "      <td>CHENNAI</td>\n",
       "      <td>2011</td>\n",
       "      <td>46000</td>\n",
       "      <td>PETROL</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>FIRST</td>\n",
       "      <td>18.2 KMPL</td>\n",
       "      <td>1199 CC</td>\n",
       "      <td>88.7 BHP</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.61 LAKH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MARUTI ERTIGA VDI</td>\n",
       "      <td>CHENNAI</td>\n",
       "      <td>2012</td>\n",
       "      <td>87000</td>\n",
       "      <td>DIESEL</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>FIRST</td>\n",
       "      <td>20.77 KMPL</td>\n",
       "      <td>1248 CC</td>\n",
       "      <td>88.76 BHP</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUDI A4 NEW 2.0 TDI MULTITRONIC</td>\n",
       "      <td>COIMBATORE</td>\n",
       "      <td>2013</td>\n",
       "      <td>40670</td>\n",
       "      <td>DIESEL</td>\n",
       "      <td>AUTOMATIC</td>\n",
       "      <td>SECOND</td>\n",
       "      <td>15.2 KMPL</td>\n",
       "      <td>1968 CC</td>\n",
       "      <td>140.8 BHP</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Name    Location  Year  Kilometers_Driven  \\\n",
       "0            MARUTI WAGON R LXI CNG      MUMBAI  2010              72000   \n",
       "1  HYUNDAI CRETA 1.6 CRDI SX OPTION        PUNE  2015              41000   \n",
       "2                      HONDA JAZZ V     CHENNAI  2011              46000   \n",
       "3                 MARUTI ERTIGA VDI     CHENNAI  2012              87000   \n",
       "4   AUDI A4 NEW 2.0 TDI MULTITRONIC  COIMBATORE  2013              40670   \n",
       "\n",
       "  Fuel_Type Transmission Owner_Type     Mileage   Engine      Power  Seats  \\\n",
       "0       CNG       MANUAL      FIRST  26.6 KM/KG   998 CC  58.16 BHP    5.0   \n",
       "1    DIESEL       MANUAL      FIRST  19.67 KMPL  1582 CC  126.2 BHP    5.0   \n",
       "2    PETROL       MANUAL      FIRST   18.2 KMPL  1199 CC   88.7 BHP    5.0   \n",
       "3    DIESEL       MANUAL      FIRST  20.77 KMPL  1248 CC  88.76 BHP    7.0   \n",
       "4    DIESEL    AUTOMATIC     SECOND   15.2 KMPL  1968 CC  140.8 BHP    5.0   \n",
       "\n",
       "   New_Price  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2  8.61 LAKH  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7253, 12)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names1 = list(all_data['Name'])\n",
    "for i in range(len(names1)) :\n",
    "    try:\n",
    "       names1[i] = names1[i].split(\" \")[0].strip().upper()\n",
    "    except :\n",
    "       pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names2 = list(all_data['Name'])\n",
    "for i in range(len(names2)) :\n",
    "    try:\n",
    "       names2[i] = names2[i].split(\" \")[1].strip().upper()\n",
    "    except :\n",
    "       pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "car_data = {}\n",
    "car_data['Brand'] = names1\n",
    "car_data['Sub_Brand'] = names2\n",
    "car_data = pd.DataFrame(car_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data['Name']=all_data['Name'].str.upper()\n",
    "all_data['Location']=all_data['Location'].str.upper()\n",
    "all_data['Fuel_Type']=all_data['Fuel_Type'].str.upper()\n",
    "all_data['Transmission']=all_data['Transmission'].str.upper()\n",
    "all_data['Owner_Type']=all_data['Owner_Type'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cleaning Engine, Power and Mileage\n",
    "\n",
    "all_data['Engine']=all_data['Engine'].str.replace('[A-Za-z]','')\n",
    "all_data['Engine'] = all_data['Engine'].str.strip()\n",
    "all_data['Engine'] = all_data['Engine'].apply(float)\n",
    "\n",
    "all_data['Power']=all_data['Power'].str.replace('[A-Za-z]','')\n",
    "all_data['Power'] = all_data['Power'].str.strip()\n",
    "all_data.Power = all_data.Power.fillna('')\n",
    "\n",
    "\n",
    "all_data['Mileage']=all_data['Mileage'].str.replace('[A-Za-z,/]','')\n",
    "all_data['Mileage'] = all_data['Mileage'].str.strip()\n",
    "all_data['Mileage'] = all_data['Mileage'].apply(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Power = list(all_data['Power'])\n",
    "\n",
    "for i in range(len(Power)) :\n",
    "    try:\n",
    "       Power[i] = float(Power[i])\n",
    "    except :\n",
    "       Power[i] = np.nan\n",
    "    \n",
    "\n",
    "num_data = {}\n",
    "num_data['Power'] = Power\n",
    "num_data = pd.DataFrame(num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del all_data['Power']\n",
    "all_data=pd.concat([all_data,num_data,car_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new = all_data['New_Price'].str.split(\" \", n = 1, expand = True) \n",
    "all_data[\"Price\"]= new[0] \n",
    "all_data['Price'] = all_data['Price'].apply(float)\n",
    "all_data[\"Currency\"]= new[1]\n",
    "\n",
    "all_data['Cr']=np.where(all_data['Currency'].str.contains('Cr'),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data[\"Final_Price\"]= np.where(all_data['Cr']==1, all_data[\"Price\"]*100, all_data[\"Price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del all_data['New_Price']\n",
    "del all_data['Price']\n",
    "del all_data['Currency']\n",
    "del all_data['Cr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data['History']=2019 - all_data['Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data['Year'] = all_data['Year'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mileage</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engine</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seats</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Power</th>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final_Price</th>\n",
       "      <td>6247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Values\n",
       "Mileage           2\n",
       "Engine           46\n",
       "Seats            53\n",
       "Power           175\n",
       "Final_Price    6247"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1=all_data.isnull().sum()\n",
    "t1=pd.DataFrame(t1)\n",
    "t1.columns=['Values']\n",
    "t1[t1.Values>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impute_val=all_data.groupby(['Brand','Sub_Brand','Fuel_Type', 'Transmission'], as_index=False)[['Seats', 'Power','Engine','Mileage']].median()\n",
    "impute_val.columns=['Brand','Sub_Brand','Fuel_Type', 'Transmission','Seats1','Power1','Engine1','Mileage1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_v2=pd.merge(all_data, impute_val, on=['Brand','Sub_Brand','Fuel_Type', 'Transmission'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_v2[\"Seats_v1\"]= np.where(all_data_v2['Seats']> 0, all_data_v2['Seats'], all_data_v2['Seats1'])\n",
    "all_data_v2[\"Power_v1\"]= np.where(all_data_v2['Power']> 0, all_data_v2['Power'], all_data_v2['Power1'])\n",
    "all_data_v2[\"Engine_v1\"]= np.where(all_data_v2['Engine']> 0, all_data_v2['Engine'], all_data_v2['Engine1'])\n",
    "all_data_v2[\"Mileage_v1\"]= np.where(all_data_v2['Mileage']> 0, all_data_v2['Mileage'], all_data_v2['Mileage1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del all_data_v2['Seats']\n",
    "del all_data_v2['Seats1']\n",
    "\n",
    "del all_data_v2['Power']\n",
    "del all_data_v2['Power1']\n",
    "\n",
    "del all_data_v2['Mileage']\n",
    "del all_data_v2['Mileage1']\n",
    "\n",
    "del all_data_v2['Engine']\n",
    "del all_data_v2['Engine1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_v2['Seats_v1']=all_data_v2['Seats_v1'].fillna(all_data_v2['Seats_v1'].median())\n",
    "all_data_v2['Power_v1']=all_data_v2['Power_v1'].fillna(all_data_v2['Power_v1'].median())\n",
    "all_data_v2['Engine_v1']=all_data_v2['Engine_v1'].fillna(all_data_v2['Engine_v1'].median())\n",
    "all_data_v2['Mileage_v1']=all_data_v2['Mileage_v1'].fillna(all_data_v2['Mileage_v1'].median())\n",
    "\n",
    "\n",
    "all_data_v2['Final_Price']=all_data_v2['Final_Price'].fillna(-999)\n",
    "\n",
    "#all_data_v2.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', 'Location', 'Year', 'Fuel_Type', 'Transmission', 'Owner_Type', 'Brand', 'Sub_Brand']\n",
      "['Kilometers_Driven', 'Final_Price', 'History', 'Seats_v1', 'Power_v1', 'Engine_v1', 'Mileage_v1']\n"
     ]
    }
   ],
   "source": [
    "cat_cols=all_data_v2.columns[all_data_v2.dtypes=='object'].tolist()\n",
    "print(cat_cols)\n",
    "\n",
    "num_cols=all_data_v2.columns[all_data_v2.dtypes!='object'].tolist()\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6001, 16)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additional Removal Part:\n",
    "train1_dup1=all_data_v2[:6019]\n",
    "test1_dup1=all_data_v2[6019:7253]\n",
    "\n",
    "train1_dup2=pd.concat([train1_dup1,tg], axis=1)\n",
    "\n",
    "train1_dup2['flag']=train1_dup2['Fuel_Type']+train1_dup2['Location']+train1_dup2['Name']+train1_dup2['Owner_Type']+train1_dup2['Transmission']+train1_dup2['Year']+train1_dup2['Brand']+train1_dup2['Sub_Brand']+train1_dup2['Kilometers_Driven'].astype(str)+train1_dup2['Final_Price'].astype(str)+ train1_dup2['History'].astype(str)+train1_dup2['Seats_v1'].astype(str)+train1_dup2['Power_v1'].astype(str)+train1_dup2['Engine_v1'].astype(str)+train1_dup2['Mileage_v1'].astype(str)\n",
    "\n",
    "dup1=train1_dup2[train1_dup2.flag.duplicated()]\n",
    "dup2=dup1.drop_duplicates(subset =\"flag\",keep='first')\n",
    "dup2=dup2[['flag']]\n",
    "\n",
    "dup_inner=pd.merge(dup2, train1_dup2, on='flag', how='inner')\n",
    "\n",
    "dup_inner2=dup_inner.groupby('flag', as_index=False).agg({\"Price\": \"mean\"})\n",
    "dup_inner2.columns = ['flag', 'Price1']\n",
    "\n",
    "dup_inner3=pd.merge(dup_inner,dup_inner2, on='flag', how='inner')\n",
    "\n",
    "dup_inner4=dup_inner3.drop_duplicates(subset =\"flag\",keep='first') \n",
    "\n",
    "del dup_inner4['flag']\n",
    "del dup_inner4['Price']\n",
    "\n",
    "dup_inner4 = dup_inner4.rename(columns = {\"Price1\": \"Price\"})\n",
    "\n",
    "train1_dup3=train1_dup2.drop_duplicates(subset =\"flag\",keep = False)\n",
    "\n",
    "del train1_dup3['flag']\n",
    "\n",
    "train1_dup4=pd.concat([train1_dup3,dup_inner4])\n",
    "train1_dup4 = train1_dup4.reset_index(drop=True)\n",
    "\n",
    "train1_dup4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "tg=train1_dup4[['Price']]\n",
    "tg[\"Price1\"] = np.log1p(tg[\"Price\"].astype(np.float64))\n",
    "\n",
    "target=tg.Price1#Change\n",
    "del train1_dup4['Price']\n",
    "\n",
    "all_data_v2=pd.concat([train1_dup4,test1_dup1])\n",
    "all_data_v2 = all_data_v2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7235, 15)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_v2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kilometers_Driven</th>\n",
       "      <th>Final_Price</th>\n",
       "      <th>History</th>\n",
       "      <th>Seats_v1</th>\n",
       "      <th>Power_v1</th>\n",
       "      <th>Engine_v1</th>\n",
       "      <th>Mileage_v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.235000e+03</td>\n",
       "      <td>7235.000000</td>\n",
       "      <td>7235.000000</td>\n",
       "      <td>7235.000000</td>\n",
       "      <td>7235.000000</td>\n",
       "      <td>7235.000000</td>\n",
       "      <td>7235.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.873222e+04</td>\n",
       "      <td>-857.326511</td>\n",
       "      <td>5.633725</td>\n",
       "      <td>5.278784</td>\n",
       "      <td>112.134200</td>\n",
       "      <td>1615.251831</td>\n",
       "      <td>18.294951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.451807e+04</td>\n",
       "      <td>352.633886</td>\n",
       "      <td>3.255190</td>\n",
       "      <td>0.807305</td>\n",
       "      <td>53.309144</td>\n",
       "      <td>594.226306</td>\n",
       "      <td>4.204655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.710000e+02</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.400000e+04</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>1198.000000</td>\n",
       "      <td>15.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.350000e+04</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>92.850000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>18.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.300000e+04</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>138.030000</td>\n",
       "      <td>1968.000000</td>\n",
       "      <td>21.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.500000e+06</td>\n",
       "      <td>99.920000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>5998.000000</td>\n",
       "      <td>33.540000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Kilometers_Driven  Final_Price      History     Seats_v1     Power_v1  \\\n",
       "count       7.235000e+03  7235.000000  7235.000000  7235.000000  7235.000000   \n",
       "mean        5.873222e+04  -857.326511     5.633725     5.278784   112.134200   \n",
       "std         8.451807e+04   352.633886     3.255190     0.807305    53.309144   \n",
       "min         1.710000e+02  -999.000000     0.000000     2.000000    34.200000   \n",
       "25%         3.400000e+04  -999.000000     3.000000     5.000000    74.000000   \n",
       "50%         5.350000e+04  -999.000000     5.000000     5.000000    92.850000   \n",
       "75%         7.300000e+04  -999.000000     8.000000     5.000000   138.030000   \n",
       "max         6.500000e+06    99.920000    23.000000    10.000000   616.000000   \n",
       "\n",
       "         Engine_v1   Mileage_v1  \n",
       "count  7235.000000  7235.000000  \n",
       "mean   1615.251831    18.294951  \n",
       "std     594.226306     4.204655  \n",
       "min      72.000000     0.000000  \n",
       "25%    1198.000000    15.290000  \n",
       "50%    1493.000000    18.160000  \n",
       "75%    1968.000000    21.100000  \n",
       "max    5998.000000    33.540000  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_v2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoding(BaseEstimator):\n",
    "    categorical_columns = None\n",
    "    return_df = False\n",
    "    random_state = 30\n",
    "    threshold = 50\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def convert_input(self, X):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            if isinstance(X, list):\n",
    "                X = pd.DataFrame(np.array(X))\n",
    "            elif isinstance(X, (np.generic, np.ndarray, pd.Series)):\n",
    "                X = pd.DataFrame(X)\n",
    "            else:\n",
    "                raise ValueError('Unexpected input type: %s' % (str(type(X))))\n",
    "            X = X.apply(lambda x: pd.to_numeric(x, errors='ignore'))\n",
    "        x = X.copy(deep = True)\n",
    "        return x\n",
    "\n",
    "    def get_categorical_columns(self, X):\n",
    "        return X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    def get_numerical_columns(self,X):\n",
    "        temp_x=X[X.columns[X.nunique()<=self.threshold]]\n",
    "        col_names=temp_x.columns[temp_x.dtypes!='object']\n",
    "        return col_names\n",
    "\n",
    "    def apply_encoding(self, X_in, encoding_dict):\n",
    "        X = self.convert_input(X_in)\n",
    "        for col in self.categorical_columns:\n",
    "            if col in encoding_dict:\n",
    "                freq_dict = encoding_dict[col]\n",
    "                X[col] = X[col].apply(lambda x: freq_dict[x] if x  in freq_dict else np.nan)\n",
    "        return X\n",
    "\n",
    "    def create_encoding_dict(self, X, y):\n",
    "        return {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if X is None:\n",
    "            raise ValueError(\"Input array is required to call fit method!\")\n",
    "        X = self.convert_input(X)\n",
    "        self.encoding_dict = self.create_encoding_dict(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = self.apply_encoding(X, self.encoding_dict)\n",
    "        if self.return_df:\n",
    "            return df\n",
    "        else:\n",
    "            return df.values\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        X = self.convert_input(X)\n",
    "        for col in self.categorical_columns:\n",
    "            freq_dict = self.encoding_dict[col]\n",
    "            for key, val in freq_dict.iteritems():\n",
    "                X.loc[X[col] == val, col] = key\n",
    "        if self.return_df:\n",
    "            return X\n",
    "        else:\n",
    "            return X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FreqeuncyEncoding(Encoding):\n",
    "    '''\n",
    "    class to perform FreqeuncyEncoding on Categorical Variables\n",
    "    Initialization Variabes:\n",
    "    categorical_columns: list of categorical columns from the dataframe\n",
    "    or list of indexes of caategorical columns for numpy ndarray\n",
    "    return_df: boolean\n",
    "        if True: returns pandas dataframe on transformation\n",
    "        else: return numpy ndarray\n",
    "    '''\n",
    "    def __init__(self, categorical_columns = None, return_df = False):\n",
    "        self.categorical_columns = categorical_columns\n",
    "        self.return_df = return_df\n",
    "\n",
    "    def create_encoding_dict(self, X, y):\n",
    "        encoding_dict = {}\n",
    "        if self.categorical_columns is None:\n",
    "            self.categorical_columns = self.get_categorical_columns(X)\n",
    "        for col in self.categorical_columns:\n",
    "            encoding_dict.update({col: X[col].value_counts(normalize = True).to_dict()})\n",
    "        return encoding_dict\n",
    "\n",
    "\n",
    "fe=FreqeuncyEncoding(categorical_columns=cat_cols,return_df=True)\n",
    "all_data_v3=fe.fit_transform(all_data_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Maximum Titles in a Cell :  1\n",
      "\n",
      "\n",
      "Number of Unique Titles :  11\n",
      "\n",
      "\n",
      "Unique Titles:\n",
      " ['MUMBAI' 'PUNE' 'CHENNAI' 'COIMBATORE' 'HYDERABAD' 'JAIPUR' 'KOCHI'\n",
      " 'KOLKATA' 'DELHI' 'BANGALORE' 'AHMEDABAD']\n"
     ]
    }
   ],
   "source": [
    "titles = list(all_data_v2['Location'])\n",
    "\n",
    "maxim = 1\n",
    "for i in titles :\n",
    "    if len(i.split(',')) > maxim:\n",
    "         maxim = len(i.split(','))\n",
    "         \n",
    "print(\"\\n\\nMaximum Titles in a Cell : \", maxim)    \n",
    "\n",
    "all_titles = []\n",
    "\n",
    "for i in titles :\n",
    "    if len(i.split(',')) == 1:\n",
    "         all_titles.append(i.split(',')[0].strip().upper())\n",
    "    else :\n",
    "        for it in range(len(i.split(','))):\n",
    "            all_titles.append(i.split(',')[it].strip().upper())\n",
    "\n",
    "print(\"\\n\\nNumber of Unique Titles : \", len(pd.Series(all_titles).unique()))\n",
    "print(\"\\n\\nUnique Titles:\\n\", pd.Series(all_titles).unique())\n",
    "\n",
    "all_titles = list(pd.Series(all_titles).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(11):\n",
    "    ttl=all_titles[i]\n",
    "    ttl1=ttl+'1'\n",
    "    all_data_v2[ttl1] = all_data_v2['Location'].str.contains(ttl)\n",
    "    all_data_v2[ttl1] = all_data_v2[ttl1].map({True: 1, False: 0}) \n",
    "    \n",
    "del all_data_v2['Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Maximum Titles in a Cell :  1\n",
      "\n",
      "\n",
      "Number of Unique Titles :  5\n",
      "\n",
      "\n",
      "Unique Titles:\n",
      " ['CNG' 'DIESEL' 'PETROL' 'LPG' 'ELECTRIC']\n"
     ]
    }
   ],
   "source": [
    "titles = list(all_data_v2['Fuel_Type'])\n",
    "\n",
    "maxim = 1\n",
    "for i in titles :\n",
    "    if len(i.split(',')) > maxim:\n",
    "         maxim = len(i.split(','))\n",
    "         \n",
    "print(\"\\n\\nMaximum Titles in a Cell : \", maxim)    \n",
    "\n",
    "all_titles = []\n",
    "\n",
    "for i in titles :\n",
    "    if len(i.split(',')) == 1:\n",
    "         all_titles.append(i.split(',')[0].strip().upper())\n",
    "    else :\n",
    "        for it in range(len(i.split(','))):\n",
    "            all_titles.append(i.split(',')[it].strip().upper())\n",
    "\n",
    "print(\"\\n\\nNumber of Unique Titles : \", len(pd.Series(all_titles).unique()))\n",
    "print(\"\\n\\nUnique Titles:\\n\", pd.Series(all_titles).unique())\n",
    "\n",
    "all_titles = list(pd.Series(all_titles).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    ttl=all_titles[i]\n",
    "    ttl2=ttl+'2'\n",
    "    all_data_v2[ttl2] = all_data_v2['Fuel_Type'].str.contains(ttl)\n",
    "    all_data_v2[ttl2] = all_data_v2[ttl2].map({True: 1, False: 0})\n",
    "    \n",
    "del all_data_v2['Fuel_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Maximum Titles in a Cell :  1\n",
      "\n",
      "\n",
      "Number of Unique Titles :  2\n",
      "\n",
      "\n",
      "Unique Titles:\n",
      " ['MANUAL' 'AUTOMATIC']\n"
     ]
    }
   ],
   "source": [
    "titles = list(all_data_v2['Transmission'])\n",
    "\n",
    "maxim = 1\n",
    "for i in titles :\n",
    "    if len(i.split(',')) > maxim:\n",
    "         maxim = len(i.split(','))\n",
    "         \n",
    "print(\"\\n\\nMaximum Titles in a Cell : \", maxim)    \n",
    "\n",
    "all_titles = []\n",
    "\n",
    "for i in titles :\n",
    "    if len(i.split(',')) == 1:\n",
    "         all_titles.append(i.split(',')[0].strip().upper())\n",
    "    else :\n",
    "        for it in range(len(i.split(','))):\n",
    "            all_titles.append(i.split(',')[it].strip().upper())\n",
    "\n",
    "print(\"\\n\\nNumber of Unique Titles : \", len(pd.Series(all_titles).unique()))\n",
    "print(\"\\n\\nUnique Titles:\\n\", pd.Series(all_titles).unique())\n",
    "\n",
    "all_titles = list(pd.Series(all_titles).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    ttl=all_titles[i]\n",
    "    ttl2=ttl+'3'\n",
    "    all_data_v2[ttl2] = all_data_v2['Transmission'].str.contains(ttl)\n",
    "    all_data_v2[ttl2] = all_data_v2[ttl2].map({True: 1, False: 0})\n",
    "    \n",
    "del all_data_v2['Transmission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Maximum Titles in a Cell :  1\n",
      "\n",
      "\n",
      "Number of Unique Titles :  4\n",
      "\n",
      "\n",
      "Unique Titles:\n",
      " ['FIRST' 'SECOND' 'FOURTH & ABOVE' 'THIRD']\n"
     ]
    }
   ],
   "source": [
    "titles = list(all_data_v2['Owner_Type'])\n",
    "\n",
    "maxim = 1\n",
    "for i in titles :\n",
    "    if len(i.split(',')) > maxim:\n",
    "         maxim = len(i.split(','))\n",
    "         \n",
    "print(\"\\n\\nMaximum Titles in a Cell : \", maxim)    \n",
    "\n",
    "all_titles = []\n",
    "\n",
    "for i in titles :\n",
    "    if len(i.split(',')) == 1:\n",
    "         all_titles.append(i.split(',')[0].strip().upper())\n",
    "    else :\n",
    "        for it in range(len(i.split(','))):\n",
    "            all_titles.append(i.split(',')[it].strip().upper())\n",
    "\n",
    "print(\"\\n\\nNumber of Unique Titles : \", len(pd.Series(all_titles).unique()))\n",
    "print(\"\\n\\nUnique Titles:\\n\", pd.Series(all_titles).unique())\n",
    "\n",
    "all_titles = list(pd.Series(all_titles).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    ttl=all_titles[i]\n",
    "    ttl2=ttl+'4'\n",
    "    all_data_v2[ttl2] = all_data_v2['Owner_Type'].str.contains(ttl)\n",
    "    all_data_v2[ttl2] = all_data_v2[ttl2].map({True: 1, False: 0})\n",
    "    \n",
    "del all_data_v2['Owner_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Maximum Titles in a Cell :  1\n",
      "\n",
      "\n",
      "Number of Unique Titles :  23\n",
      "\n",
      "\n",
      "Unique Titles:\n",
      " ['2010' '2015' '2011' '2012' '2013' '2016' '2018' '2014' '2017' '2007'\n",
      " '2009' '2008' '2019' '2006' '2005' '2004' '2002' '2000' '2003' '1999'\n",
      " '2001' '1998' '1996']\n"
     ]
    }
   ],
   "source": [
    "titles = list(all_data_v2['Year'])\n",
    "\n",
    "maxim = 1\n",
    "for i in titles :\n",
    "    if len(i.split(',')) > maxim:\n",
    "         maxim = len(i.split(','))\n",
    "         \n",
    "print(\"\\n\\nMaximum Titles in a Cell : \", maxim)    \n",
    "\n",
    "all_titles = []\n",
    "\n",
    "for i in titles :\n",
    "    if len(i.split(',')) == 1:\n",
    "         all_titles.append(i.split(',')[0].strip().upper())\n",
    "    else :\n",
    "        for it in range(len(i.split(','))):\n",
    "            all_titles.append(i.split(',')[it].strip().upper())\n",
    "\n",
    "print(\"\\n\\nNumber of Unique Titles : \", len(pd.Series(all_titles).unique()))\n",
    "print(\"\\n\\nUnique Titles:\\n\", pd.Series(all_titles).unique())\n",
    "\n",
    "all_titles = list(pd.Series(all_titles).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(23):\n",
    "    ttl=all_titles[i]\n",
    "    ttl2=ttl+'_5'\n",
    "    all_data_v2[ttl2] = all_data_v2['Year'].str.contains(ttl)\n",
    "    all_data_v2[ttl2] = all_data_v2[ttl2].map({True: 1, False: 0})\n",
    "    \n",
    "del all_data_v2['Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Maximum Titles in a Cell :  1\n",
      "\n",
      "\n",
      "Number of Unique Titles :  32\n",
      "\n",
      "\n",
      "Unique Titles:\n",
      " ['MARUTI' 'HYUNDAI' 'HONDA' 'AUDI' 'NISSAN' 'TOYOTA' 'VOLKSWAGEN' 'TATA'\n",
      " 'LAND' 'MITSUBISHI' 'RENAULT' 'MERCEDES-BENZ' 'BMW' 'MAHINDRA' 'FORD'\n",
      " 'PORSCHE' 'DATSUN' 'JAGUAR' 'VOLVO' 'CHEVROLET' 'SKODA' 'MINI' 'FIAT'\n",
      " 'JEEP' 'SMART' 'AMBASSADOR' 'ISUZU' 'FORCE' 'BENTLEY' 'LAMBORGHINI'\n",
      " 'HINDUSTAN' 'OPELCORSA']\n"
     ]
    }
   ],
   "source": [
    "titles = list(all_data_v2['Brand'])\n",
    "\n",
    "maxim = 1\n",
    "for i in titles :\n",
    "    if len(i.split(',')) > maxim:\n",
    "         maxim = len(i.split(','))\n",
    "         \n",
    "print(\"\\n\\nMaximum Titles in a Cell : \", maxim)    \n",
    "\n",
    "all_titles = []\n",
    "\n",
    "for i in titles :\n",
    "    if len(i.split(',')) == 1:\n",
    "         all_titles.append(i.split(',')[0].strip().upper())\n",
    "    else :\n",
    "        for it in range(len(i.split(','))):\n",
    "            all_titles.append(i.split(',')[it].strip().upper())\n",
    "\n",
    "print(\"\\n\\nNumber of Unique Titles : \", len(pd.Series(all_titles).unique()))\n",
    "print(\"\\n\\nUnique Titles:\\n\", pd.Series(all_titles).unique())\n",
    "\n",
    "all_titles = list(pd.Series(all_titles).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(32):\n",
    "    ttl=all_titles[i]\n",
    "    ttl2=ttl+'_6'\n",
    "    all_data_v2[ttl2] = all_data_v2['Brand'].str.contains(ttl)\n",
    "    all_data_v2[ttl2] = all_data_v2[ttl2].map({True: 1, False: 0})\n",
    "    \n",
    "del all_data_v2['Brand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Maximum Titles in a Cell :  1\n",
      "\n",
      "\n",
      "Number of Unique Titles :  218\n",
      "\n",
      "\n",
      "Unique Titles:\n",
      " ['WAGON' 'CRETA' 'JAZZ' 'ERTIGA' 'A4' 'EON' 'MICRA' 'INNOVA' 'VENTO'\n",
      " 'INDICA' 'CIAZ' 'CITY' 'SWIFT' 'ROVER' 'PAJERO' 'AMAZE' 'DUSTER' 'NEW'\n",
      " '3' 'S' 'A6' 'I20' 'ALTO' 'WRV' 'COROLLA' 'SSANGYONG' 'VITARA' 'KUV'\n",
      " 'M-CLASS' 'POLO' 'NANO' 'ELANTRA' 'XCENT' 'THAR' 'GRAND' 'KWID' 'I10'\n",
      " 'X-TRAIL' 'ZEN' 'FIGO' 'C-CLASS' 'CAYENNE' 'XUV500' 'TERRANO' 'BRIO'\n",
      " 'FIESTA' 'SANTRO' 'ZEST' 'RITZ' '5' 'FORTUNER' 'ECOSPORT' 'VERNA' 'GO'\n",
      " 'OMNI' 'ETIOS' 'XF' 'EECO' 'CIVIC' 'V40' 'B' 'SCORPIO' 'CR-V' 'SLC' '1'\n",
      " 'BEAT' 'RAPID' 'RS5' 'SUPERB' 'X5' 'GLC' 'COUNTRYMAN' 'OPTRA' 'LODGY'\n",
      " 'E-CLASS' 'BALENO' 'LAURA' 'NUVOSPORT' 'FABIA' 'INDIGO' 'Q3' 'OCTAVIA'\n",
      " 'A8' 'VERITO' 'COOPER' 'SANTA' 'X1' 'ACCENT' 'TUCSON' 'GLE' 'A-STAR'\n",
      " 'GRANDE' 'X3' 'Q7' 'JETTA' 'GLA' 'CELERIO' 'SUMO' 'ACCORD' '6' 'MANZA'\n",
      " 'SPARK' 'CLUBMAN' 'TEANA' '800' 'BRV' 'XE' 'XENON' 'A3' 'GL-CLASS' 'BR-V'\n",
      " 'S80' 'CAPTUR' 'ENJOY' 'BOLERO' 'CEDIA' 'S-CROSS' 'YETI' 'ENDEAVOUR'\n",
      " 'GLS' 'A' 'SX4' 'CAMRY' 'MOBILIO' 'LINEA' 'TT' 'RENAULT' 'COMPASS' 'IKON'\n",
      " 'SAIL' 'QUANTO' 'AVEO' 'XYLO' 'ESTEEM' 'SAFARI' 'IGNIS' 'XJ' 'SUNNY'\n",
      " 'SLK-CLASS' 'PASSAT' 'Q5' 'DZIRE' 'CRUZE' 'KOLEOS' 'QUALIS' 'AMEO'\n",
      " 'REDI-GO' 'FORTWO' 'OUTLANDER' 'CAYMAN' 'CLA' 'XC60' 'BOXSTER' 'XUV300'\n",
      " 'HEXA' 'TIAGO' '7' 'AVVENTURA' 'TIGOR' 'S60' 'CLASSIC' 'BEETLE' 'PETRA'\n",
      " 'GETZ' 'A7' 'ELITE' 'ASPIRE' 'TIGUAN' 'CAPTIVA' 'PUNTO' 'TUV' 'X6' 'BOLT'\n",
      " 'EVALIA' 'SCALA' 'JEEP' 'SONATA' 'FREESTYLE' 'LOGAN' 'TAVERA' 'ESTILO'\n",
      " 'XC90' 'PULSE' 'MONTERO' 'PANAMERA' 'CROSSPOLO' 'FLUENCE' 'VENTURE'\n",
      " 'NEXON' 'MUX' 'PLATINUM' 'R-CLASS' 'CLS-CLASS' 'D-MAX' 'S-CLASS' 'LANCER'\n",
      " 'REDI' 'E' 'MUSTANG' 'FUSION' 'SIENA' '1000' 'SL-CLASS' 'Z4' 'PRIUS'\n",
      " 'ONE' 'VERSA' 'WR-V' 'CONTINENTAL' 'GALLARDO' 'F' 'MOTORS' 'FLYING'\n",
      " 'LAND' 'MU' '370Z' 'ABARTH' '1.4GSI']\n"
     ]
    }
   ],
   "source": [
    "titles = list(all_data_v2['Sub_Brand'])\n",
    "\n",
    "maxim = 1\n",
    "for i in titles :\n",
    "    if len(i.split(',')) > maxim:\n",
    "         maxim = len(i.split(','))\n",
    "         \n",
    "print(\"\\n\\nMaximum Titles in a Cell : \", maxim)    \n",
    "\n",
    "all_titles = []\n",
    "\n",
    "for i in titles :\n",
    "    if len(i.split(',')) == 1:\n",
    "         all_titles.append(i.split(',')[0].strip().upper())\n",
    "    else :\n",
    "        for it in range(len(i.split(','))):\n",
    "            all_titles.append(i.split(',')[it].strip().upper())\n",
    "\n",
    "print(\"\\n\\nNumber of Unique Titles : \", len(pd.Series(all_titles).unique()))\n",
    "print(\"\\n\\nUnique Titles:\\n\", pd.Series(all_titles).unique())\n",
    "\n",
    "all_titles = list(pd.Series(all_titles).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(218):\n",
    "    ttl=all_titles[i]\n",
    "    ttl2=ttl+'_6'\n",
    "    all_data_v2[ttl2] = all_data_v2['Sub_Brand'].str.contains(ttl)\n",
    "    all_data_v2[ttl2] = all_data_v2[ttl2].map({True: 1, False: 0})\n",
    "    \n",
    "del all_data_v2['Sub_Brand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Kilometers_Driven', 'Final_Price', 'History', 'Seats_v1',\n",
       "       'Power_v1', 'Engine_v1', 'Mileage_v1', 'MUMBAI1', 'PUNE1',\n",
       "       ...\n",
       "       'WR-V_6', 'CONTINENTAL_6', 'GALLARDO_6', 'F_6', 'MOTORS_6', 'FLYING_6',\n",
       "       'MU_6', '370Z_6', 'ABARTH_6', '1.4GSI_6'],\n",
       "      dtype='object', length=300)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_v2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Location', 'Year', 'Kilometers_Driven', 'Fuel_Type',\n",
       "       'Transmission', 'Owner_Type', 'Brand', 'Sub_Brand', 'Final_Price',\n",
       "       'History', 'Seats_v1', 'Power_v1', 'Engine_v1', 'Mileage_v1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_v3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_v4=all_data_v3[['Name', 'Location', 'Year', 'Fuel_Type', 'Transmission', 'Owner_Type', 'Brand', 'Sub_Brand']]\n",
    "\n",
    "del all_data_v2['Name']\n",
    "#del all_data_v2['Sub_Brand']\n",
    "\n",
    "all_data_v5=pd.concat([all_data_v2,all_data_v4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1=all_data_v5[:6001]\n",
    "test1=all_data_v5[6001:7235]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Selection Step:\n",
    "model1=xgb.XGBRegressor(colsample_bylevel=0.95, \n",
    "                       colsample_bytree=0.95,\n",
    "                       gamma=1, #1\n",
    "                       learning_rate=0.1, #0.1\n",
    "                       max_depth=15,#14\n",
    "                       min_child_weight=1, \n",
    "                       n_estimators=600, #500\n",
    "                       objective='reg:linear', \n",
    "                       reg_alpha=1, \n",
    "                       reg_lambda=1,\n",
    "                       scale_pos_weight=1, \n",
    "                       seed=99, \n",
    "                       subsample=0.95,\n",
    "                       silent=True)\n",
    "model1.fit(train1, target)\n",
    "\n",
    "t1=model1.feature_importances_\n",
    "t1=pd.DataFrame(t1)\n",
    "\n",
    "t2=train1.columns\n",
    "t2=pd.DataFrame(t2)\n",
    "\n",
    "t1.columns=['Importance']\n",
    "t2.columns=['Variable']\n",
    "\n",
    "t3=pd.concat([t2,t1],axis=1)\n",
    "t4=t3[t3['Importance'] > 0]\n",
    "\n",
    "my_cols = list(t4.Variable)\n",
    "all_data_new_v1 = all_data_v5[my_cols]\n",
    "all_data_new_v1.head()\n",
    "\n",
    "train1=all_data_new_v1[:6001]\n",
    "test1=all_data_new_v1[6001:7235]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "import math\n",
    "def rmsle(real, predicted):\n",
    "    real=np.expm1(real)\n",
    "    predicted=np.expm1(predicted)\n",
    "    return np.sqrt(mean_squared_log_error(real,predicted))\n",
    "    \n",
    "def rmsle_lgb(labels, preds):\n",
    "    return 'rmsle', rmsle(preds,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=30.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "[0]\tvalidation_0-rmse:1.46843\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.159559\n",
      "[400]\tvalidation_0-rmse:0.145732\n",
      "[600]\tvalidation_0-rmse:0.142043\n",
      "[800]\tvalidation_0-rmse:0.140366\n",
      "[1000]\tvalidation_0-rmse:0.138808\n",
      "[1200]\tvalidation_0-rmse:0.137813\n",
      "[1400]\tvalidation_0-rmse:0.13724\n",
      "[1600]\tvalidation_0-rmse:0.137027\n",
      "[1800]\tvalidation_0-rmse:0.136662\n",
      "[2000]\tvalidation_0-rmse:0.136868\n",
      "[2200]\tvalidation_0-rmse:0.136838\n",
      "[2400]\tvalidation_0-rmse:0.136783\n",
      "Stopping. Best iteration:\n",
      "[1835]\tvalidation_0-rmse:0.136613\n",
      "\n",
      "errxgb:  0.13661279023753073\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.38013\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.159703\n",
      "[400]\tvalidation_0-rmse:0.144504\n",
      "[600]\tvalidation_0-rmse:0.141998\n",
      "[800]\tvalidation_0-rmse:0.140628\n",
      "[1000]\tvalidation_0-rmse:0.139375\n",
      "[1200]\tvalidation_0-rmse:0.138802\n",
      "[1400]\tvalidation_0-rmse:0.138246\n",
      "[1600]\tvalidation_0-rmse:0.137785\n",
      "[1800]\tvalidation_0-rmse:0.137778\n",
      "[2000]\tvalidation_0-rmse:0.137636\n",
      "[2200]\tvalidation_0-rmse:0.137554\n",
      "[2400]\tvalidation_0-rmse:0.137241\n",
      "[2600]\tvalidation_0-rmse:0.136965\n",
      "[2800]\tvalidation_0-rmse:0.136965\n",
      "[3000]\tvalidation_0-rmse:0.136965\n",
      "Stopping. Best iteration:\n",
      "[2560]\tvalidation_0-rmse:0.136965\n",
      "\n",
      "errxgb:  0.13696528491228882\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.54066\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.166115\n",
      "[400]\tvalidation_0-rmse:0.144567\n",
      "[600]\tvalidation_0-rmse:0.137253\n",
      "[800]\tvalidation_0-rmse:0.134071\n",
      "[1000]\tvalidation_0-rmse:0.131973\n",
      "[1200]\tvalidation_0-rmse:0.130411\n",
      "[1400]\tvalidation_0-rmse:0.129354\n",
      "[1600]\tvalidation_0-rmse:0.128857\n",
      "[1800]\tvalidation_0-rmse:0.128496\n",
      "[2000]\tvalidation_0-rmse:0.128181\n",
      "[2200]\tvalidation_0-rmse:0.127882\n",
      "[2400]\tvalidation_0-rmse:0.127835\n",
      "[2600]\tvalidation_0-rmse:0.127557\n",
      "[2800]\tvalidation_0-rmse:0.127599\n",
      "[3000]\tvalidation_0-rmse:0.127599\n",
      "Stopping. Best iteration:\n",
      "[2593]\tvalidation_0-rmse:0.127557\n",
      "\n",
      "errxgb:  0.1275563545399171\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.72046\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.171567\n",
      "[400]\tvalidation_0-rmse:0.150218\n",
      "[600]\tvalidation_0-rmse:0.143457\n",
      "[800]\tvalidation_0-rmse:0.140333\n",
      "[1000]\tvalidation_0-rmse:0.138388\n",
      "[1200]\tvalidation_0-rmse:0.136762\n",
      "[1400]\tvalidation_0-rmse:0.136011\n",
      "[1600]\tvalidation_0-rmse:0.135507\n",
      "[1800]\tvalidation_0-rmse:0.135029\n",
      "[2000]\tvalidation_0-rmse:0.134569\n",
      "[2200]\tvalidation_0-rmse:0.134361\n",
      "[2400]\tvalidation_0-rmse:0.134126\n",
      "[2600]\tvalidation_0-rmse:0.13402\n",
      "[2800]\tvalidation_0-rmse:0.133968\n",
      "[3000]\tvalidation_0-rmse:0.133968\n",
      "[3200]\tvalidation_0-rmse:0.133968\n",
      "Stopping. Best iteration:\n",
      "[2637]\tvalidation_0-rmse:0.133961\n",
      "\n",
      "errxgb:  0.13396139485854294\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.10304\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.117673\n",
      "[400]\tvalidation_0-rmse:0.108131\n",
      "[600]\tvalidation_0-rmse:0.106212\n",
      "[800]\tvalidation_0-rmse:0.105009\n",
      "[1000]\tvalidation_0-rmse:0.104309\n",
      "[1200]\tvalidation_0-rmse:0.103801\n",
      "[1400]\tvalidation_0-rmse:0.103948\n",
      "[1600]\tvalidation_0-rmse:0.10376\n",
      "[1800]\tvalidation_0-rmse:0.103435\n",
      "[2000]\tvalidation_0-rmse:0.103061\n",
      "[2200]\tvalidation_0-rmse:0.103791\n",
      "[2400]\tvalidation_0-rmse:0.103889\n",
      "[2600]\tvalidation_0-rmse:0.103935\n",
      "Stopping. Best iteration:\n",
      "[2025]\tvalidation_0-rmse:0.103022\n",
      "\n",
      "errxgb:  0.1030217438999293\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.4929\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.181533\n",
      "[400]\tvalidation_0-rmse:0.169609\n",
      "[600]\tvalidation_0-rmse:0.165731\n",
      "[800]\tvalidation_0-rmse:0.164491\n",
      "[1000]\tvalidation_0-rmse:0.163841\n",
      "[1200]\tvalidation_0-rmse:0.163461\n",
      "[1400]\tvalidation_0-rmse:0.163023\n",
      "[1600]\tvalidation_0-rmse:0.163021\n",
      "[1800]\tvalidation_0-rmse:0.162872\n",
      "[2000]\tvalidation_0-rmse:0.162838\n",
      "[2200]\tvalidation_0-rmse:0.163238\n",
      "[2400]\tvalidation_0-rmse:0.163364\n",
      "Stopping. Best iteration:\n",
      "[1887]\tvalidation_0-rmse:0.162779\n",
      "\n",
      "errxgb:  0.16277862364116466\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.60865\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.161507\n",
      "[400]\tvalidation_0-rmse:0.142451\n",
      "[600]\tvalidation_0-rmse:0.137323\n",
      "[800]\tvalidation_0-rmse:0.134859\n",
      "[1000]\tvalidation_0-rmse:0.133152\n",
      "[1200]\tvalidation_0-rmse:0.131928\n",
      "[1400]\tvalidation_0-rmse:0.131258\n",
      "[1600]\tvalidation_0-rmse:0.131034\n",
      "[1800]\tvalidation_0-rmse:0.130887\n",
      "[2000]\tvalidation_0-rmse:0.130489\n",
      "[2200]\tvalidation_0-rmse:0.130431\n",
      "[2400]\tvalidation_0-rmse:0.130305\n",
      "[2600]\tvalidation_0-rmse:0.130267\n",
      "[2800]\tvalidation_0-rmse:0.130314\n",
      "[3000]\tvalidation_0-rmse:0.13034\n",
      "Stopping. Best iteration:\n",
      "[2524]\tvalidation_0-rmse:0.130214\n",
      "\n",
      "errxgb:  0.1302138915921732\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.14569\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.130304\n",
      "[400]\tvalidation_0-rmse:0.113292\n",
      "[600]\tvalidation_0-rmse:0.110396\n",
      "[800]\tvalidation_0-rmse:0.108312\n",
      "[1000]\tvalidation_0-rmse:0.107616\n",
      "[1200]\tvalidation_0-rmse:0.106583\n",
      "[1400]\tvalidation_0-rmse:0.106276\n",
      "[1600]\tvalidation_0-rmse:0.105955\n",
      "[1800]\tvalidation_0-rmse:0.105448\n",
      "[2000]\tvalidation_0-rmse:0.105154\n",
      "[2200]\tvalidation_0-rmse:0.104798\n",
      "[2400]\tvalidation_0-rmse:0.104809\n",
      "[2600]\tvalidation_0-rmse:0.104677\n",
      "[2800]\tvalidation_0-rmse:0.104643\n",
      "[3000]\tvalidation_0-rmse:0.104464\n",
      "[3200]\tvalidation_0-rmse:0.104439\n",
      "[3400]\tvalidation_0-rmse:0.104439\n",
      "[3600]\tvalidation_0-rmse:0.104439\n",
      "Stopping. Best iteration:\n",
      "[3051]\tvalidation_0-rmse:0.104439\n",
      "\n",
      "errxgb:  0.1044383386081834\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.27654\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.138646\n",
      "[400]\tvalidation_0-rmse:0.122598\n",
      "[600]\tvalidation_0-rmse:0.117696\n",
      "[800]\tvalidation_0-rmse:0.115456\n",
      "[1000]\tvalidation_0-rmse:0.114116\n",
      "[1200]\tvalidation_0-rmse:0.112996\n",
      "[1400]\tvalidation_0-rmse:0.112272\n",
      "[1600]\tvalidation_0-rmse:0.111887\n",
      "[1800]\tvalidation_0-rmse:0.111276\n",
      "[2000]\tvalidation_0-rmse:0.110536\n",
      "[2200]\tvalidation_0-rmse:0.110346\n",
      "[2400]\tvalidation_0-rmse:0.110186\n",
      "[2600]\tvalidation_0-rmse:0.110043\n",
      "[2800]\tvalidation_0-rmse:0.109962\n",
      "[3000]\tvalidation_0-rmse:0.109962\n",
      "[3200]\tvalidation_0-rmse:0.109962\n",
      "Stopping. Best iteration:\n",
      "[2639]\tvalidation_0-rmse:0.109962\n",
      "\n",
      "errxgb:  0.10996179496205025\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.31226\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.169438\n",
      "[400]\tvalidation_0-rmse:0.152918\n",
      "[600]\tvalidation_0-rmse:0.148692\n",
      "[800]\tvalidation_0-rmse:0.14672\n",
      "[1000]\tvalidation_0-rmse:0.14457\n",
      "[1200]\tvalidation_0-rmse:0.14324\n",
      "[1400]\tvalidation_0-rmse:0.142253\n",
      "[1600]\tvalidation_0-rmse:0.141909\n",
      "[1800]\tvalidation_0-rmse:0.141526\n",
      "[2000]\tvalidation_0-rmse:0.141253\n",
      "[2200]\tvalidation_0-rmse:0.141009\n",
      "[2400]\tvalidation_0-rmse:0.140777\n",
      "[2600]\tvalidation_0-rmse:0.140619\n",
      "[2800]\tvalidation_0-rmse:0.140451\n",
      "[3000]\tvalidation_0-rmse:0.140451\n",
      "[3200]\tvalidation_0-rmse:0.140451\n",
      "Stopping. Best iteration:\n",
      "[2703]\tvalidation_0-rmse:0.140417\n",
      "\n",
      "errxgb:  0.14041774759116263\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.1476\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.131314\n",
      "[400]\tvalidation_0-rmse:0.124396\n",
      "[600]\tvalidation_0-rmse:0.124832\n",
      "[800]\tvalidation_0-rmse:0.124375\n",
      "[1000]\tvalidation_0-rmse:0.123088\n",
      "[1200]\tvalidation_0-rmse:0.122441\n",
      "[1400]\tvalidation_0-rmse:0.122538\n",
      "[1600]\tvalidation_0-rmse:0.12228\n",
      "[1800]\tvalidation_0-rmse:0.122287\n",
      "[2000]\tvalidation_0-rmse:0.121794\n",
      "[2200]\tvalidation_0-rmse:0.122049\n",
      "[2400]\tvalidation_0-rmse:0.121869\n",
      "[2600]\tvalidation_0-rmse:0.121815\n",
      "[2800]\tvalidation_0-rmse:0.121659\n",
      "[3000]\tvalidation_0-rmse:0.121729\n",
      "[3200]\tvalidation_0-rmse:0.121654\n",
      "Stopping. Best iteration:\n",
      "[2687]\tvalidation_0-rmse:0.121601\n",
      "\n",
      "errxgb:  0.12160059875519094\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.17237\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.150383\n",
      "[400]\tvalidation_0-rmse:0.137288\n",
      "[600]\tvalidation_0-rmse:0.132018\n",
      "[800]\tvalidation_0-rmse:0.128575\n",
      "[1000]\tvalidation_0-rmse:0.127477\n",
      "[1200]\tvalidation_0-rmse:0.126582\n",
      "[1400]\tvalidation_0-rmse:0.125386\n",
      "[1600]\tvalidation_0-rmse:0.124994\n",
      "[1800]\tvalidation_0-rmse:0.124691\n",
      "[2000]\tvalidation_0-rmse:0.124589\n",
      "[2200]\tvalidation_0-rmse:0.123863\n",
      "[2400]\tvalidation_0-rmse:0.123585\n",
      "[2600]\tvalidation_0-rmse:0.123463\n",
      "[2800]\tvalidation_0-rmse:0.123592\n",
      "[3000]\tvalidation_0-rmse:0.123384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3200]\tvalidation_0-rmse:0.123384\n",
      "[3400]\tvalidation_0-rmse:0.123384\n",
      "Stopping. Best iteration:\n",
      "[2968]\tvalidation_0-rmse:0.123371\n",
      "\n",
      "errxgb:  0.12337054876064653\n",
      "###\n",
      "[0]\tvalidation_0-rmse:2.06325\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.24714\n",
      "[400]\tvalidation_0-rmse:0.220103\n",
      "[600]\tvalidation_0-rmse:0.211218\n",
      "[800]\tvalidation_0-rmse:0.207046\n",
      "[1000]\tvalidation_0-rmse:0.204701\n",
      "[1200]\tvalidation_0-rmse:0.203143\n",
      "[1400]\tvalidation_0-rmse:0.202148\n",
      "[1600]\tvalidation_0-rmse:0.201364\n",
      "[1800]\tvalidation_0-rmse:0.200821\n",
      "[2000]\tvalidation_0-rmse:0.200409\n",
      "[2200]\tvalidation_0-rmse:0.200365\n",
      "[2400]\tvalidation_0-rmse:0.200365\n",
      "[2600]\tvalidation_0-rmse:0.200365\n",
      "Stopping. Best iteration:\n",
      "[2005]\tvalidation_0-rmse:0.200365\n",
      "\n",
      "errxgb:  0.20036505221216672\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.62944\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.153421\n",
      "[400]\tvalidation_0-rmse:0.13316\n",
      "[600]\tvalidation_0-rmse:0.126783\n",
      "[800]\tvalidation_0-rmse:0.123581\n",
      "[1000]\tvalidation_0-rmse:0.121547\n",
      "[1200]\tvalidation_0-rmse:0.120376\n",
      "[1400]\tvalidation_0-rmse:0.11942\n",
      "[1600]\tvalidation_0-rmse:0.119037\n",
      "[1800]\tvalidation_0-rmse:0.118435\n",
      "[2000]\tvalidation_0-rmse:0.11802\n",
      "[2200]\tvalidation_0-rmse:0.1179\n",
      "[2400]\tvalidation_0-rmse:0.117775\n",
      "[2600]\tvalidation_0-rmse:0.117556\n",
      "[2800]\tvalidation_0-rmse:0.117556\n",
      "[3000]\tvalidation_0-rmse:0.117556\n",
      "Stopping. Best iteration:\n",
      "[2551]\tvalidation_0-rmse:0.117551\n",
      "\n",
      "errxgb:  0.11755125992267702\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.14814\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.151802\n",
      "[400]\tvalidation_0-rmse:0.134415\n",
      "[600]\tvalidation_0-rmse:0.128821\n",
      "[800]\tvalidation_0-rmse:0.126938\n",
      "[1000]\tvalidation_0-rmse:0.125681\n",
      "[1200]\tvalidation_0-rmse:0.124705\n",
      "[1400]\tvalidation_0-rmse:0.12384\n",
      "[1600]\tvalidation_0-rmse:0.123481\n",
      "[1800]\tvalidation_0-rmse:0.123361\n",
      "[2000]\tvalidation_0-rmse:0.123051\n",
      "[2200]\tvalidation_0-rmse:0.122663\n",
      "[2400]\tvalidation_0-rmse:0.122426\n",
      "[2600]\tvalidation_0-rmse:0.122056\n",
      "[2800]\tvalidation_0-rmse:0.121806\n",
      "[3000]\tvalidation_0-rmse:0.121795\n",
      "[3200]\tvalidation_0-rmse:0.121795\n",
      "Stopping. Best iteration:\n",
      "[2733]\tvalidation_0-rmse:0.121783\n",
      "\n",
      "errxgb:  0.1217828682678267\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.16057\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.154199\n",
      "[400]\tvalidation_0-rmse:0.148252\n",
      "[600]\tvalidation_0-rmse:0.14664\n",
      "[800]\tvalidation_0-rmse:0.145814\n",
      "[1000]\tvalidation_0-rmse:0.145553\n",
      "[1200]\tvalidation_0-rmse:0.145547\n",
      "[1400]\tvalidation_0-rmse:0.145145\n",
      "[1600]\tvalidation_0-rmse:0.145144\n",
      "[1800]\tvalidation_0-rmse:0.144961\n",
      "[2000]\tvalidation_0-rmse:0.144696\n",
      "[2200]\tvalidation_0-rmse:0.144544\n",
      "[2400]\tvalidation_0-rmse:0.144415\n",
      "[2600]\tvalidation_0-rmse:0.144248\n",
      "[2800]\tvalidation_0-rmse:0.144429\n",
      "[3000]\tvalidation_0-rmse:0.144429\n",
      "Stopping. Best iteration:\n",
      "[2593]\tvalidation_0-rmse:0.144208\n",
      "\n",
      "errxgb:  0.14420816165331454\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.20586\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.146849\n",
      "[400]\tvalidation_0-rmse:0.133428\n",
      "[600]\tvalidation_0-rmse:0.130701\n",
      "[800]\tvalidation_0-rmse:0.12899\n",
      "[1000]\tvalidation_0-rmse:0.129022\n",
      "[1200]\tvalidation_0-rmse:0.128708\n",
      "[1400]\tvalidation_0-rmse:0.128099\n",
      "[1600]\tvalidation_0-rmse:0.128229\n",
      "[1800]\tvalidation_0-rmse:0.128421\n",
      "[2000]\tvalidation_0-rmse:0.12858\n",
      "Stopping. Best iteration:\n",
      "[1481]\tvalidation_0-rmse:0.127997\n",
      "\n",
      "errxgb:  0.12799742617107868\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.55301\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.154262\n",
      "[400]\tvalidation_0-rmse:0.138295\n",
      "[600]\tvalidation_0-rmse:0.134198\n",
      "[800]\tvalidation_0-rmse:0.131321\n",
      "[1000]\tvalidation_0-rmse:0.129436\n",
      "[1200]\tvalidation_0-rmse:0.128561\n",
      "[1400]\tvalidation_0-rmse:0.127822\n",
      "[1600]\tvalidation_0-rmse:0.127458\n",
      "[1800]\tvalidation_0-rmse:0.127151\n",
      "[2000]\tvalidation_0-rmse:0.127013\n",
      "[2200]\tvalidation_0-rmse:0.127039\n",
      "[2400]\tvalidation_0-rmse:0.126794\n",
      "[2600]\tvalidation_0-rmse:0.126628\n",
      "[2800]\tvalidation_0-rmse:0.12656\n",
      "[3000]\tvalidation_0-rmse:0.12653\n",
      "[3200]\tvalidation_0-rmse:0.126529\n",
      "[3400]\tvalidation_0-rmse:0.126529\n",
      "Stopping. Best iteration:\n",
      "[2902]\tvalidation_0-rmse:0.126484\n",
      "\n",
      "errxgb:  0.12648328767731493\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.26954\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.174212\n",
      "[400]\tvalidation_0-rmse:0.159313\n",
      "[600]\tvalidation_0-rmse:0.155589\n",
      "[800]\tvalidation_0-rmse:0.152967\n",
      "[1000]\tvalidation_0-rmse:0.151081\n",
      "[1200]\tvalidation_0-rmse:0.150222\n",
      "[1400]\tvalidation_0-rmse:0.149785\n",
      "[1600]\tvalidation_0-rmse:0.148718\n",
      "[1800]\tvalidation_0-rmse:0.148504\n",
      "[2000]\tvalidation_0-rmse:0.148155\n",
      "[2200]\tvalidation_0-rmse:0.147739\n",
      "[2400]\tvalidation_0-rmse:0.14739\n",
      "[2600]\tvalidation_0-rmse:0.147156\n",
      "[2800]\tvalidation_0-rmse:0.146757\n",
      "[3000]\tvalidation_0-rmse:0.146684\n",
      "[3200]\tvalidation_0-rmse:0.146684\n",
      "[3400]\tvalidation_0-rmse:0.146684\n",
      "Stopping. Best iteration:\n",
      "[2917]\tvalidation_0-rmse:0.14667\n",
      "\n",
      "errxgb:  0.14666988574115997\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.14487\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.145534\n",
      "[400]\tvalidation_0-rmse:0.134463\n",
      "[600]\tvalidation_0-rmse:0.129494\n",
      "[800]\tvalidation_0-rmse:0.126377\n",
      "[1000]\tvalidation_0-rmse:0.125018\n",
      "[1200]\tvalidation_0-rmse:0.123089\n",
      "[1400]\tvalidation_0-rmse:0.121669\n",
      "[1600]\tvalidation_0-rmse:0.120734\n",
      "[1800]\tvalidation_0-rmse:0.120087\n",
      "[2000]\tvalidation_0-rmse:0.119139\n",
      "[2200]\tvalidation_0-rmse:0.118815\n",
      "[2400]\tvalidation_0-rmse:0.118663\n",
      "[2600]\tvalidation_0-rmse:0.1188\n",
      "[2800]\tvalidation_0-rmse:0.118548\n",
      "[3000]\tvalidation_0-rmse:0.118552\n",
      "[3200]\tvalidation_0-rmse:0.118552\n",
      "Stopping. Best iteration:\n",
      "[2766]\tvalidation_0-rmse:0.118531\n",
      "\n",
      "errxgb:  0.11853045232225981\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.3736\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.159966\n",
      "[400]\tvalidation_0-rmse:0.14322\n",
      "[600]\tvalidation_0-rmse:0.137628\n",
      "[800]\tvalidation_0-rmse:0.135284\n",
      "[1000]\tvalidation_0-rmse:0.13468\n",
      "[1200]\tvalidation_0-rmse:0.13323\n",
      "[1400]\tvalidation_0-rmse:0.133062\n",
      "[1600]\tvalidation_0-rmse:0.132585\n",
      "[1800]\tvalidation_0-rmse:0.131962\n",
      "[2000]\tvalidation_0-rmse:0.131727\n",
      "[2200]\tvalidation_0-rmse:0.131726\n",
      "[2400]\tvalidation_0-rmse:0.131739\n",
      "[2600]\tvalidation_0-rmse:0.131647\n",
      "[2800]\tvalidation_0-rmse:0.13177\n",
      "[3000]\tvalidation_0-rmse:0.131704\n",
      "[3200]\tvalidation_0-rmse:0.131704\n",
      "Stopping. Best iteration:\n",
      "[2637]\tvalidation_0-rmse:0.131608\n",
      "\n",
      "errxgb:  0.13160750314668998\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.45876\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.168754\n",
      "[400]\tvalidation_0-rmse:0.155433\n",
      "[600]\tvalidation_0-rmse:0.150047\n",
      "[800]\tvalidation_0-rmse:0.147273\n",
      "[1000]\tvalidation_0-rmse:0.144941\n",
      "[1200]\tvalidation_0-rmse:0.143354\n",
      "[1400]\tvalidation_0-rmse:0.142857\n",
      "[1600]\tvalidation_0-rmse:0.142226\n",
      "[1800]\tvalidation_0-rmse:0.14162\n",
      "[2000]\tvalidation_0-rmse:0.141239\n",
      "[2200]\tvalidation_0-rmse:0.141096\n",
      "[2400]\tvalidation_0-rmse:0.141016\n",
      "[2600]\tvalidation_0-rmse:0.140823\n",
      "[2800]\tvalidation_0-rmse:0.140818\n",
      "[3000]\tvalidation_0-rmse:0.140877\n",
      "[3200]\tvalidation_0-rmse:0.140893\n",
      "Stopping. Best iteration:\n",
      "[2629]\tvalidation_0-rmse:0.140693\n",
      "\n",
      "errxgb:  0.14069296829425051\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.21609\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.171844\n",
      "[400]\tvalidation_0-rmse:0.144814\n",
      "[600]\tvalidation_0-rmse:0.137335\n",
      "[800]\tvalidation_0-rmse:0.133868\n",
      "[1000]\tvalidation_0-rmse:0.132051\n",
      "[1200]\tvalidation_0-rmse:0.130773\n",
      "[1400]\tvalidation_0-rmse:0.129986\n",
      "[1600]\tvalidation_0-rmse:0.129276\n",
      "[1800]\tvalidation_0-rmse:0.12866\n",
      "[2000]\tvalidation_0-rmse:0.12788\n",
      "[2200]\tvalidation_0-rmse:0.127223\n",
      "[2400]\tvalidation_0-rmse:0.126718\n",
      "[2600]\tvalidation_0-rmse:0.126513\n",
      "[2800]\tvalidation_0-rmse:0.126335\n",
      "[3000]\tvalidation_0-rmse:0.126335\n",
      "[3200]\tvalidation_0-rmse:0.126335\n",
      "Stopping. Best iteration:\n",
      "[2695]\tvalidation_0-rmse:0.126316\n",
      "\n",
      "errxgb:  0.1263165749176833\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.12358\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.152718\n",
      "[400]\tvalidation_0-rmse:0.136007\n",
      "[600]\tvalidation_0-rmse:0.130484\n",
      "[800]\tvalidation_0-rmse:0.128414\n",
      "[1000]\tvalidation_0-rmse:0.127137\n",
      "[1200]\tvalidation_0-rmse:0.126188\n",
      "[1400]\tvalidation_0-rmse:0.124959\n",
      "[1600]\tvalidation_0-rmse:0.124837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1800]\tvalidation_0-rmse:0.124537\n",
      "[2000]\tvalidation_0-rmse:0.123796\n",
      "[2200]\tvalidation_0-rmse:0.123802\n",
      "[2400]\tvalidation_0-rmse:0.12384\n",
      "[2600]\tvalidation_0-rmse:0.123542\n",
      "[2800]\tvalidation_0-rmse:0.123248\n",
      "[3000]\tvalidation_0-rmse:0.123182\n",
      "[3200]\tvalidation_0-rmse:0.123108\n",
      "[3400]\tvalidation_0-rmse:0.123108\n",
      "[3600]\tvalidation_0-rmse:0.123108\n",
      "Stopping. Best iteration:\n",
      "[3014]\tvalidation_0-rmse:0.123067\n",
      "\n",
      "errxgb:  0.12306641451523896\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.18199\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.130957\n",
      "[400]\tvalidation_0-rmse:0.114496\n",
      "[600]\tvalidation_0-rmse:0.110321\n",
      "[800]\tvalidation_0-rmse:0.109381\n",
      "[1000]\tvalidation_0-rmse:0.108768\n",
      "[1200]\tvalidation_0-rmse:0.107996\n",
      "[1400]\tvalidation_0-rmse:0.107295\n",
      "[1600]\tvalidation_0-rmse:0.107104\n",
      "[1800]\tvalidation_0-rmse:0.107066\n",
      "[2000]\tvalidation_0-rmse:0.107108\n",
      "[2200]\tvalidation_0-rmse:0.107118\n",
      "[2400]\tvalidation_0-rmse:0.106842\n",
      "[2600]\tvalidation_0-rmse:0.106818\n",
      "[2800]\tvalidation_0-rmse:0.106766\n",
      "[3000]\tvalidation_0-rmse:0.106763\n",
      "Stopping. Best iteration:\n",
      "[2543]\tvalidation_0-rmse:0.106624\n",
      "\n",
      "errxgb:  0.10662422147539909\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.3474\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.158713\n",
      "[400]\tvalidation_0-rmse:0.146706\n",
      "[600]\tvalidation_0-rmse:0.142845\n",
      "[800]\tvalidation_0-rmse:0.140409\n",
      "[1000]\tvalidation_0-rmse:0.139402\n",
      "[1200]\tvalidation_0-rmse:0.13846\n",
      "[1400]\tvalidation_0-rmse:0.138493\n",
      "[1600]\tvalidation_0-rmse:0.138306\n",
      "[1800]\tvalidation_0-rmse:0.138246\n",
      "[2000]\tvalidation_0-rmse:0.138346\n",
      "Stopping. Best iteration:\n",
      "[1517]\tvalidation_0-rmse:0.138044\n",
      "\n",
      "errxgb:  0.13804318180810923\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.16918\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.133567\n",
      "[400]\tvalidation_0-rmse:0.111358\n",
      "[600]\tvalidation_0-rmse:0.105101\n",
      "[800]\tvalidation_0-rmse:0.102138\n",
      "[1000]\tvalidation_0-rmse:0.0999\n",
      "[1200]\tvalidation_0-rmse:0.098127\n",
      "[1400]\tvalidation_0-rmse:0.096601\n",
      "[1600]\tvalidation_0-rmse:0.09625\n",
      "[1800]\tvalidation_0-rmse:0.095546\n",
      "[2000]\tvalidation_0-rmse:0.095105\n",
      "[2200]\tvalidation_0-rmse:0.094162\n",
      "[2400]\tvalidation_0-rmse:0.093899\n",
      "[2600]\tvalidation_0-rmse:0.09366\n",
      "[2800]\tvalidation_0-rmse:0.093349\n",
      "[3000]\tvalidation_0-rmse:0.09338\n",
      "[3200]\tvalidation_0-rmse:0.09338\n",
      "Stopping. Best iteration:\n",
      "[2785]\tvalidation_0-rmse:0.093349\n",
      "\n",
      "errxgb:  0.09334870996411625\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.51513\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.181806\n",
      "[400]\tvalidation_0-rmse:0.163318\n",
      "[600]\tvalidation_0-rmse:0.157489\n",
      "[800]\tvalidation_0-rmse:0.154667\n",
      "[1000]\tvalidation_0-rmse:0.152688\n",
      "[1200]\tvalidation_0-rmse:0.151049\n",
      "[1400]\tvalidation_0-rmse:0.150642\n",
      "[1600]\tvalidation_0-rmse:0.150026\n",
      "[1800]\tvalidation_0-rmse:0.149594\n",
      "[2000]\tvalidation_0-rmse:0.148942\n",
      "[2200]\tvalidation_0-rmse:0.148731\n",
      "[2400]\tvalidation_0-rmse:0.148419\n",
      "[2600]\tvalidation_0-rmse:0.148193\n",
      "[2800]\tvalidation_0-rmse:0.148014\n",
      "[3000]\tvalidation_0-rmse:0.148014\n",
      "[3200]\tvalidation_0-rmse:0.148014\n",
      "Stopping. Best iteration:\n",
      "[2733]\tvalidation_0-rmse:0.148014\n",
      "\n",
      "errxgb:  0.14801448817729526\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.19203\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.102607\n",
      "[400]\tvalidation_0-rmse:0.092404\n",
      "[600]\tvalidation_0-rmse:0.090085\n",
      "[800]\tvalidation_0-rmse:0.088869\n",
      "[1000]\tvalidation_0-rmse:0.088437\n",
      "[1200]\tvalidation_0-rmse:0.088038\n",
      "[1400]\tvalidation_0-rmse:0.088248\n",
      "[1600]\tvalidation_0-rmse:0.087908\n",
      "[1800]\tvalidation_0-rmse:0.088187\n",
      "[2000]\tvalidation_0-rmse:0.088023\n",
      "Stopping. Best iteration:\n",
      "[1552]\tvalidation_0-rmse:0.087749\n",
      "\n",
      "errxgb:  0.08774887605466884\n",
      "###\n",
      "[0]\tvalidation_0-rmse:1.27799\n",
      "Will train until validation_0-rmse hasn't improved in 600 rounds.\n",
      "[200]\tvalidation_0-rmse:0.15403\n",
      "[400]\tvalidation_0-rmse:0.137755\n",
      "[600]\tvalidation_0-rmse:0.132422\n",
      "[800]\tvalidation_0-rmse:0.130068\n",
      "[1000]\tvalidation_0-rmse:0.128492\n",
      "[1200]\tvalidation_0-rmse:0.127846\n",
      "[1400]\tvalidation_0-rmse:0.126833\n",
      "[1600]\tvalidation_0-rmse:0.126431\n",
      "[1800]\tvalidation_0-rmse:0.125892\n",
      "[2000]\tvalidation_0-rmse:0.125553\n",
      "[2200]\tvalidation_0-rmse:0.124943\n",
      "[2400]\tvalidation_0-rmse:0.124646\n",
      "[2600]\tvalidation_0-rmse:0.124408\n",
      "[2800]\tvalidation_0-rmse:0.124206\n",
      "[3000]\tvalidation_0-rmse:0.124206\n",
      "[3200]\tvalidation_0-rmse:0.124206\n",
      "Stopping. Best iteration:\n",
      "[2743]\tvalidation_0-rmse:0.124198\n",
      "\n",
      "errxgb:  0.12419721262909698\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=30, shuffle=True, random_state=1234) #30\n",
    "predicts = []\n",
    "predicts_train = []\n",
    "errxgb=[]\n",
    "for train_index, test_index in kf.split(train1, target):\n",
    "    print(\"###\")\n",
    "    X_train, X_val = train1.iloc[train_index], train1.iloc[test_index]\n",
    "    y_train, y_val = target.iloc[train_index], target.iloc[test_index]\n",
    "    xgb_params = {'n_estimators': 30000,\n",
    "                  'n_jobs': -1,\n",
    "                  'learning_rate':0.05, #0.05\n",
    "                  'random_state':1234, \n",
    "                  'max_depth':7, #Done:7\n",
    "                  'reg_alpha':1,\n",
    "                  'colsample_bytree':0.1, #Done:0.1\n",
    "                  'subsample':1, #1\n",
    "                  'seed':1234 \n",
    "                  }\n",
    "    clf=XGBRegressor(**xgb_params)\n",
    "    clf.fit(X_train, y_train,eval_set=[(X_val, y_val)],verbose=200,eval_metric='rmse',early_stopping_rounds=600)\n",
    "    \n",
    "    pr=clf.predict(X_val)\n",
    "    print(\"errxgb: \",rmsle_lgb(y_val.values,pr)[1])    \n",
    "    errxgb.append(rmsle_lgb(y_val.values,pr)[1])\n",
    "    \n",
    "    predicts_train.append(clf.predict(train1))\n",
    "    predicts.append(clf.predict(test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1284715885769709"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(errxgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s=pd.DataFrame({'Price':np.expm1(np.mean(predicts,0))}) #max, mean, min, median\n",
    "s.to_excel('xgb_impute_v3_mean.xlsx', index=False)#0.9438"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s=pd.DataFrame({'Price':np.expm1(np.min(predicts,0))}) #max, mean, min, median\n",
    "s.to_excel('xgb_impute_v3_min.xlsx', index=False)#0.9367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s=pd.DataFrame({'Price':np.expm1(np.max(predicts,0))}) #max, mean, min, median\n",
    "s.to_excel('xgb_impute_v3_max.xlsx', index=False)#0.9410"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s=pd.DataFrame({'Price':np.expm1(np.median(predicts,0))}) #max, mean, min, median\n",
    "s.to_excel('xgb_impute_v3_median.xlsx', index=False)#0.9440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For Stacking:\n",
    "s=pd.DataFrame({'xgb_Price':(np.median(predicts_train,0))}) #max, mean, min\n",
    "chk1=tg[['Price1']]\n",
    "s1=pd.concat([s,chk1], axis=1)\n",
    "s1.to_excel('xgb_train.xlsx', index=False)\n",
    "\n",
    "s=pd.DataFrame({'xgb_Price':(np.median(predicts,0))}) #max, mean, min\n",
    "s.to_excel('xgb_test.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Subsample:\n",
    "#0.5:0.9438\n",
    "#0.9:0.9438\n",
    "#0.6:0.9438\n",
    "#0.8:0.9439\n",
    "#0.4:0.9434\n",
    "#0.7:0.9439\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#CV:\n",
    "#30:0.9423\n",
    "#5:0.9416\n",
    "#20:0.9421\n",
    "#10:0.9421\n",
    "#15:0.9421\n",
    "#25:0.9421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#colsample_bytree:\n",
    "#1:0.9385\n",
    "#0.9:0.9394\n",
    "#0.8:0.9405\n",
    "#0.7:0.9406\n",
    "#0.6:0.9405\n",
    "#0.5:0.9402\n",
    "#0.4:0.9417\n",
    "#0.3:0.9425\n",
    "#0.2:0.9425\n",
    "#0.1:0.9440\n",
    "#0.07:0.9428\n",
    "#0.125:0.9437\n",
    "\n",
    "#12:0.9436\n",
    "#11:0.9436\n",
    "#10:0.9437\n",
    "#9:0.9439\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#0.3:0.9423\n",
    "#0.2:0.9423\n",
    "#0.4:0.9417\n",
    "#0.1:0.9435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Depth:\n",
    "#0.1,8:0.9435\n",
    "#0.1,4:0.9428\n",
    "#0.1,7:0.9438\n",
    "#0.1,5:0.9431\n",
    "#0.1,6:0.9435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Learning Rate:\n",
    "#0.1,7,0.05:0.9438\n",
    "#0.1,7,0.1:0.9432\n",
    "#0.1,7,0.2:0.9422\n",
    "#0.1,7,0.3:0.9412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CV:\n",
    "#20:0.9437\n",
    "#5:0.9428\n",
    "#15:0.9437\n",
    "#25:0.9437\n",
    "#10:0.9434\n",
    "#35:0.9436"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Outlier removal colsample:\n",
    "#0.1,30:0.9432\n",
    "#0.1,15:0.9431\n",
    "#0.1,25:0.9431\n",
    "#0.1,10:0.9429\n",
    "#0.1,20:0.9432\n",
    "\n",
    "#0.2,30:0.9424\n",
    "#0.3,30:0.9422\n",
    "\n",
    "#0.1,15:0.9431\n",
    "#0.2,15:0.9425\n",
    "#0.3,15:0.9421\n",
    "\n",
    "#0.1,25:0.9431\n",
    "\n",
    "#30,4,0.1:0.9419\n",
    "#30,6,0.1:0.9430\n",
    "#30,5,0.1:\n",
    "\n",
    "#0.1,7,10:0.9429\n",
    "#0.1,7,20:0.9432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
